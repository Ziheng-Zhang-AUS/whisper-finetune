{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"./cache/huggingface\"\n",
    "from ctranslate2.converters import TransformersConverter\n",
    "from transformers.models.whisper.convert_openai_to_hf import (\n",
    "    convert_openai_whisper_to_tfms,\n",
    ")\n",
    "from huggingface_hub import HfApi\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def download_model_from_wandb(run_path: str, file_path: str, save_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a model file from Weights & Biases and return the local file path.\n",
    "\n",
    "    Parameters:\n",
    "    - run_path: str. Path to the W&B run, e.g., \"i4ds/whisper4sg/runs/28z8x0k4\".\n",
    "    - file_path: str. Path to the file in the W&B run, e.g., \"40569234_output/last_model.pt\".\n",
    "    - save_dir: str. Local directory to save the file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The local path to the downloaded file.\n",
    "    \"\"\"\n",
    "    # Initialize W&B API\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # Fetch the run\n",
    "    run = api.run(run_path)\n",
    "\n",
    "    # File save path\n",
    "    save_path = f\"{save_dir}/{file_path.split('/')[-1]}\"\n",
    "\n",
    "    # Download the file\n",
    "    run.file(file_path).download(root=save_dir, replace=True)\n",
    "\n",
    "    return save_path\n",
    "\n",
    "# Example usage\n",
    "run_path = \"i4ds/whisper4sg/runs/8z6vbiwl\"\n",
    "file_path = \"42907404_output/best_model.pt\"\n",
    "save_dir = \"./downloaded_models\"\n",
    "hu_model_path = \"i4ds/whisper4sg-8-folds-best\"\n",
    "\n",
    "model_local_path = download_model_from_wandb(run_path, file_path, save_dir)\n",
    "print(model_local_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_folder = Path(save_dir, 'hf_model')\n",
    "hf_model_folder.mkdir(exist_ok=True)\n",
    "ctranslate2_model_folder = Path('ct2_output')\n",
    "\n",
    "# Convert to Huggingface Model\n",
    "hf_model = convert_openai_whisper_to_tfms(os.path.join(save_dir, file_path), hf_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model[0].save_pretrained(hf_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(\"cache/tokenizer.json\", Path(hf_model_folder, \"tokenizer.json\"))\n",
    "shutil.copyfile(\"cache/config.json\", Path(hf_model_folder, \"config.json\"))\n",
    "\n",
    "# Create readme\n",
    "readme_content = f\"\"\"\n",
    "# Model Information\n",
    "\n",
    "This folder contains a converted model using ctranslate2.\n",
    "\n",
    "## Wandb log\n",
    "https://wandb.ai/{run_path}\n",
    "\n",
    "## Files\n",
    "- `tokenizer.json`: Tokenizer file.\n",
    "- `config.json`: Configuration file.\n",
    "\n",
    "## Conversion Details\n",
    "The model was converted to ctranslate2 format with float16 quantization.\n",
    "\"\"\"\n",
    "with open(Path(hf_model_folder, \"README.md\"), 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "# Convert to ctranslate2\n",
    "converter = TransformersConverter(\n",
    "    hf_model_folder,\n",
    "    copy_files=[\"tokenizer.json\", \"README.md\"],\n",
    "    load_as_float16=True \n",
    ")\n",
    "\n",
    "converter.convert(output_dir=ctranslate2_model_folder, quantization=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=\"ct2_output\",\n",
    "    repo_id=hu_model_path,\n",
    "    repo_type='model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperModel(hu_model_path, device=\"cuda\", compute_type=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"01d2eb96-4aa2-488d-ae29-22a57c3acc10_79311_109311.mp3\", beam_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
