{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenfus/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.ao.quantization import (\n",
    "  get_default_qconfig_mapping,\n",
    "  get_default_qat_qconfig_mapping,\n",
    "  QConfigMapping,\n",
    ")\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "import copy\n",
    "import whisper\n",
    "from whisper import log_mel_spectrogram\n",
    "from whisper_finetune.data.utils import process_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since i4ds/sds-stt-spc-validation couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/kenfus/.cache/huggingface/datasets/i4ds___sds-stt-spc-validation/default/0.0.0/f3f1cb44356edd8246a3fb61da2300b4be5984e1 (last modified on Sun Apr  7 17:29:40 2024).\n"
     ]
    }
   ],
   "source": [
    "ds = process_dataset(['i4ds/sds-stt-spc-validation'], [3], 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model('tiny', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenfus/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "whisper_model.eval()\n",
    "\n",
    "# Specify quantization configuration\n",
    "whisper_model.qconfig = torch.quantization.get_default_qat_qconfig()\n",
    "\n",
    "# Prepare the whisper_model\n",
    "whisper_model = torch.quantization.prepare(whisper_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torch.tensor(ds[0]['audio']['array'], dtype=torch.float)\n",
    "text = ds[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|0.68|> Haben Sie mit dieser Unterstützung gerechnet?<|4.02|><|4.08|> Am kommenden Freitag trifft Gladbach auf Wolfsburg.<|6.80|><|6.98|> Der Sieg der Opposition ist auch ein Schlappe für Park.<|14.54|><|15.44|> Darin drohen zwei IS-Kämpfer Deutschland und Bundeskanzlerin Angela Merkel.<|23.38|><|25.18|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model.forward(audio.unsqueeze(0), text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hu_whisper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhu_whisper\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hu_whisper' is not defined"
     ]
    }
   ],
   "source": [
    "hu_whisper = Whisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = whisper_model.transcribe('01d2eb96-4aa2-488d-ae29-22a57c3acc10_79311_109311.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "calculate_qparams should not be called for PlaceholderObserver",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhisper_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:550\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m    549\u001b[0m     module \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 550\u001b[0m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    554\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:588\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    587\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 588\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    589\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:588\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    587\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 588\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    589\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "    \u001b[0;31m[... skipping similar frames: _convert at line 588 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:588\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    587\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 588\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    589\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:590\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    587\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    588\u001b[0m         _convert(mod, mapping, \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# inplace\u001b[39;00m\n\u001b[1;32m    589\u001b[0m                  is_reference, convert_custom_config_dict)\n\u001b[0;32m--> 590\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    593\u001b[0m     module\u001b[38;5;241m.\u001b[39m_modules[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/quantize.py:623\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    621\u001b[0m         new_mod \u001b[38;5;241m=\u001b[39m qmod\u001b[38;5;241m.\u001b[39mfrom_float(mod, weight_qparams)\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 623\u001b[0m         new_mod \u001b[38;5;241m=\u001b[39m \u001b[43mqmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     swapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m swapped:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# Preserve module's pre forward hooks. They'll be called on quantized input\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/nn/quantized/modules/linear.py:274\u001b[0m, in \u001b[0;36mLinear.from_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    272\u001b[0m weight_post_process(mod\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m    273\u001b[0m dtype \u001b[38;5;241m=\u001b[39m weight_post_process\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 274\u001b[0m act_scale, act_zp \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mqint8, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight observer must have dtype torch.qint8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    276\u001b[0m qweight \u001b[38;5;241m=\u001b[39m _quantize_weight(mod\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mfloat(), weight_post_process)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper_finetune/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1370\u001b[0m, in \u001b[0;36mPlaceholderObserver.calculate_qparams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_qparams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate_qparams should not be called for PlaceholderObserver\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: calculate_qparams should not be called for PlaceholderObserver"
     ]
    }
   ],
   "source": [
    "quantized_model = torch.quantization.convert(whisper_model, inplace=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
