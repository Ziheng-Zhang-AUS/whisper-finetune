model:
  init_name: large-v3
  fp16: False # cast model to fp16
dataset:
  train_datasets: [i4ds/STT_SRG_DEBUG]
  val_datasets: [i4ds/STT_SRG_DEBUG]
  no_timestamp_training: False
  max_prompt_length: 223
  prompt_use_rate: 0.5
  no_timestamp_rate: 0.5
  batch_size: 1
  batch_size_eval: 16
lr_scheduler:
  type: cosine_with_warmup_restarts_chill
  num_cycles: 3
  warmup_steps: 500
  lr_gamma: 0.5
  lr_num_cycles: 3
  chill_steps: 100
  chill_range: 0.02
optimizer:
  type: adamw
  8bit: True
  params:
    lr: 0.0001
    weight_decay: 0.1
    betas: (0.9, 0.98)
    eps: 1.0e-9
    amsgrad: False
training:
  accum_grad_steps: 2
  train_only_decoder: False
  warmup_steps: 500
  max_grad_norm: 1.0
  train_steps: 2
  eval_steps: 1
  eval_warmup: 0
  eval_steps_early: 500
  save_all_checkpoints: False
  fp16: True # Use 16-bit precision for training (torch AMP)
augmentation:
  spec_augment:
    apply: True
    time_mask_param: 100
    p: 1.0
    freq_mask_param: 27
seed: 123
save_dir: ./output